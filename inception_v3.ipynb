{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaoqitong/anaconda/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nets import inception_utils, inception_v3\n",
    "from glob import glob\n",
    "import imageio\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_checkpoint_init_fn():\n",
    "    # Load from .ckpt file\n",
    "    variables_to_restore = slim.get_variables_to_restore(exclude=[\"InceptionV3/Logits/Conv2d_1c_1x1/weights:0\", \"InceptionV3/Logits/Conv2d_1c_1x1/biases:0\"])\n",
    "    global_step_reset = tf.assign(tf.train.get_or_create_global_step(), 0)\n",
    "    slim_init_fn = slim.assign_from_checkpoint_fn(\"./inception_v3.ckpt\",variables_to_restore,ignore_missing_vars=True)\n",
    "    return slim_init_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "if sys.platform == \"darwin\":\n",
    "    base_skin_dir = os.path.join('./Data/')\n",
    "else:\n",
    "    base_skin_dir = os.path.join('/datacommons/plusds/skin_cancer/team2')\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "# Set Params\n",
    "MAX_EPOCH = 30000\n",
    "NUM_CLASSES = 7\n",
    "NUM_IMG_FROM_EACH_CLASS = 9\n",
    "input_size = NUM_IMG_FROM_EACH_CLASS * NUM_CLASSES\n",
    "VALIDATION_INTERVAL = 1000\n",
    "\n",
    "session_config = tf.ConfigProto(log_device_placement=False)\n",
    "session_config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary for Loading Resized Images\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(base_skin_dir, 'HAM10000_images_part_[1-2]_resize', '*.jpg'))}\n",
    "\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'dermatofibroma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "\n",
    "# Side Information DataFrame\n",
    "\n",
    "side_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\n",
    "side_df['path'] = side_df['image_id'].map(imageid_path_dict.get)\n",
    "side_df['cell_type'] = side_df['dx'].map(lesion_type_dict.get) \n",
    "side_df['cell_type_idx'] = pd.Categorical(side_df['cell_type']).codes\n",
    "\n",
    "image_by_type = [side_df.iloc[np.array(side_df[\"cell_type_idx\"] == i)] for i in range(len(lesion_type_dict))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "one_hot_encoder = OneHotEncoder(NUM_CLASSES)\n",
    "one_hot_encoder.fit(np.arange(NUM_CLASSES).reshape(-1,1))\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    img_holder = tf.placeholder(shape=[input_size,299,299,3], dtype=tf.float32, name=\"Img_Holder\")\n",
    "    label_holder = tf.placeholder(shape=[input_size,7], dtype=tf.float32, name=\"Label_Holder\")\n",
    "    img = tf.Variable(img_holder, name=\"Img_Var\", trainable=False)\n",
    "    label = tf.Variable(label_holder, name=\"Label_Var\", trainable=False)\n",
    "    img_assign = img.assign(img_holder, name=\"Img_Assign\")\n",
    "    label_assign = label.assign(label_holder, name=\"Label_Assign\")\n",
    "    \n",
    "    img_holder_val = tf.placeholder(shape=[input_size,299,299,3], dtype=tf.float32, name=\"Img_Holder_val\")\n",
    "    label_holder_val = tf.placeholder(shape=[input_size,7], dtype=tf.float32, name=\"Label_Holder_val\")\n",
    "    img_val = tf.Variable(img_holder_val, name=\"Img_Var_val\", trainable=False)\n",
    "    label_val = tf.Variable(label_holder_val, name=\"Label_Var_val\", trainable=False)\n",
    "    img_assign_val = img_val.assign(img_holder_val, name=\"Img_Assign_val\")\n",
    "    label_assign_val = label_val.assign(label_holder_val, name=\"Label_Assign_val\")\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((img_holder,label_holder)).batch(input_size)\n",
    "#     iterator = dataset.make_initializable_iterator()\n",
    "#     image, label = iterator.get_next()\n",
    "    with slim.arg_scope(inception_v3.inception_v3_arg_scope()) as scope:\n",
    "        logits, end_points = inception_v3.inception_v3(img, num_classes=7, create_aux_logits=False)\n",
    "        scope.reuse_variables()\n",
    "        val_logits, _ = inception_v3.inception_v3(img_val, num_classes=7, create_aux_logits=False, is_training=False)\n",
    "    loss = tf.losses.softmax_cross_entropy(label, logits)\n",
    "    learning_rate = tf.train.exponential_decay(1e-04, tf.train.get_or_create_global_step(), input_size / 64 * 2.5 , 0.94)\n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_tensor = slim.learning.create_train_op(loss, optimizer=opt)\n",
    "    # Creat Summary\n",
    "    slim.summaries.add_scalar_summary(loss, 'cross_entropy_loss', 'losses')\n",
    "    slim.summaries.add_scalar_summary(learning_rate, 'learning_rate', 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_step_fn(sess, train_op, global_step, train_step_kwargs):\n",
    "    \"\"\"\n",
    "    slim.learning.train_step():\n",
    "    train_step_kwargs = {summary_writer:, should_log:, should_stop:}\n",
    "    \"\"\"\n",
    "#     train_step_fn.step += 1  # or use global_step.eval(session=sess)\n",
    "    input_path = np.array([image_by_type[i][\"path\"].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "    input_images = np.array([imageio.imread(i) for i in input_path]).astype(np.float32)\n",
    "    labels = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "    input_images, labels = shuffle(input_images, labels)\n",
    "    labels = one_hot_encoder.transform(labels).toarray()\n",
    "    \n",
    "    sess.run([img_assign,label_assign], feed_dict={img_holder:input_images, label_holder:labels})\n",
    "#     print sess.run([img,label])\n",
    "\n",
    "    # calc training losses\n",
    "    total_loss, should_stop = slim.learning.train_step(sess, train_op, global_step, train_step_kwargs)\n",
    "\n",
    "\n",
    "    # validate on interval\n",
    "#     if global_step.eval(session=sess) % VALIDATION_INTERVAL == 0:\n",
    "#         validiate_loss, validation_delta = sess.run([val_loss, summary_validation_delta])\n",
    "#     print(\">> global step {}:    train={}   validation={}  delta={}\".format(train_step_fn.step, \n",
    "#                         total_loss, validiate_loss, validiate_loss-total_loss))\n",
    "\n",
    "\n",
    "    return [total_loss, should_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "        \n",
    "#     tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, )\n",
    "    \n",
    "    input_path = np.array([image_by_type[i][\"path\"].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "    input_images = np.array([imageio.imread(i) for i in input_path]).astype(np.float32)\n",
    "#     input_size = np.shape(input_images)[0]\n",
    "    labels = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "    input_images, labels = shuffle(input_images, labels)\n",
    "    labels = one_hot_encoder.transform(labels).toarray()\n",
    "\n",
    "    slim.learning.train(\n",
    "        train_tensor,\n",
    "        \"./saved_model/\",\n",
    "        log_every_n_steps=300,\n",
    "        number_of_steps=MAX_EPOCH,\n",
    "        graph=g,\n",
    "        save_summaries_secs=300,\n",
    "        save_interval_secs=600,\n",
    "        init_fn=get_checkpoint_init_fn(),\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        train_step_fn = train_step_fn,\n",
    "        session_config=session_config,\n",
    "        init_feed_dict = {img_holder:input_images, label_holder:labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"./saved_model/model.ckpt-1458\")\n",
    "        sess.run(img.assign(shuffle(np.hstack([np.array([imageio.imread(i) for i in np.array([image_by_type[i][\"path\"].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]).reshape(-1)]).astype(np.float32).reshape(input_size, -1), one_hot_encoder.transform(np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)).toarray().reshape(input_size,-1)]))))\n",
    "        print sess.run([tf.argmax(logits[i]) for i in range(input_size)])\n",
    "        print sess.run([tf.argmax(img[:,-7:][i]) for i in range(input_size)])\n",
    "        print sess.run(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
