{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nets import inception_utils, inception_v3\n",
    "from glob import glob\n",
    "import imageio\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_checkpoint_init_fn():\n",
    "    # Load from .ckpt file\n",
    "    variables_to_restore = slim.get_variables_to_restore(exclude=[\"InceptionV3/Logits/Conv2d_1c_1x1/weights:0\", \"InceptionV3/Logits/Conv2d_1c_1x1/biases:0\"])\n",
    "    global_step_reset = tf.assign(tf.train.get_or_create_global_step(), 0)\n",
    "    slim_init_fn = slim.assign_from_checkpoint_fn(\"./inception_v3.ckpt\",variables_to_restore,ignore_missing_vars=True)\n",
    "    return slim_init_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "if sys.platform == \"darwin\":\n",
    "    base_skin_dir = os.path.join('./Data/')\n",
    "else:\n",
    "    base_skin_dir = os.path.join('/datacommons/plusds/skin_cancer/team2')\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "# Set Params\n",
    "MAX_EPOCH = 50000\n",
    "NUM_CLASSES = 7\n",
    "NUM_IMG_FROM_EACH_CLASS = 9\n",
    "input_size = NUM_IMG_FROM_EACH_CLASS * NUM_CLASSES\n",
    "VALIDATION_INTERVAL = 500\n",
    "START_LR = 1e-04\n",
    "DECAY_STEP = 10000 / 63 * 2.5\n",
    "DECAY_RATE = 0.94\n",
    "LOG_DIR = \"./saved_model/Inception_\" + str(START_LR) + \"_\" + str(DECAY_STEP) + \"_\" + str(DECAY_RATE)\n",
    "\n",
    "session_config = tf.ConfigProto(log_device_placement=False)\n",
    "session_config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary for Loading Resized Images\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(base_skin_dir, 'HAM10000_images_part_[1-2]_resize', '*.jpg'))}\n",
    "\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'dermatofibroma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "\n",
    "# Side Information DataFrame\n",
    "\n",
    "side_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\n",
    "side_df['path'] = side_df['image_id'].map(imageid_path_dict.get)\n",
    "side_df['cell_type'] = side_df['dx'].map(lesion_type_dict.get) \n",
    "side_df['cell_type_idx'] = pd.Categorical(side_df['cell_type']).codes\n",
    "\n",
    "image_by_type = [side_df.iloc[np.array(side_df[\"cell_type_idx\"] == i)] for i in range(len(lesion_type_dict))]\n",
    "image_by_type_train = [i.head(int(np.ceil(len(i)*0.9))) for i in image_by_type]\n",
    "image_by_type_val = [i.tail(int(np.floor(len(i)*0.1))) for i in image_by_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "one_hot_encoder = OneHotEncoder(NUM_CLASSES)\n",
    "one_hot_encoder.fit(np.arange(NUM_CLASSES).reshape(-1,1))\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    img_holder = tf.placeholder(shape=[input_size,299,299,3], dtype=tf.float32, name=\"Img_Holder\")\n",
    "    label_holder = tf.placeholder(shape=[input_size,7], dtype=tf.float32, name=\"Label_Holder\")\n",
    "    img = tf.Variable(img_holder, name=\"Img_Var\", trainable=False)\n",
    "    label = tf.Variable(label_holder, name=\"Label_Var\", trainable=False)\n",
    "    img_assign = img.assign(img_holder, name=\"Img_Assign\")\n",
    "    label_assign = label.assign(label_holder, name=\"Label_Assign\")\n",
    "    \n",
    "    img_holder_val = tf.placeholder(shape=[input_size,299,299,3], dtype=tf.float32, name=\"Img_Holder_val\")\n",
    "    label_holder_val = tf.placeholder(shape=[input_size,7], dtype=tf.float32, name=\"Label_Holder_val\")\n",
    "    img_val = tf.Variable(img_holder_val, name=\"Img_Var_val\", trainable=False)\n",
    "    label_val = tf.Variable(label_holder_val, name=\"Label_Var_val\", trainable=False)\n",
    "    img_assign_val = img_val.assign(img_holder_val, name=\"Img_Assign_val\")\n",
    "    label_assign_val = label_val.assign(label_holder_val, name=\"Label_Assign_val\")\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((img_holder,label_holder)).batch(input_size)\n",
    "#     iterator = dataset.make_initializable_iterator()\n",
    "#     image, label = iterator.get_next()\n",
    "    with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n",
    "        logits, end_points = inception_v3.inception_v3(img, num_classes=7, create_aux_logits=False, is_training=True)\n",
    "        logits_val, _ = inception_v3.inception_v3(img_val, num_classes=7, create_aux_logits=False, is_training=False, reuse=tf.AUTO_REUSE)\n",
    "    loss = tf.losses.softmax_cross_entropy(label, logits)\n",
    "    total_loss = tf.losses.get_total_loss()\n",
    "    loss_val = tf.losses.softmax_cross_entropy(label_val, logits_val, loss_collection=\"validation\")\n",
    "    \n",
    "    learning_rate = tf.train.exponential_decay(START_LR, tf.train.get_or_create_global_step(), DECAY_STEP, DECAY_RATE)\n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_tensor = slim.learning.create_train_op(total_loss, optimizer=opt)\n",
    "    # Creat Summary\n",
    "    slim.summaries.add_scalar_summary(total_loss, 'cross_entropy_loss', 'losses')\n",
    "    slim.summaries.add_scalar_summary(learning_rate, 'learning_rate', 'training')\n",
    "    slim.summaries.add_scalar_summary(loss_val, 'validation_loss', 'losses')\n",
    "    slim.summaries.add_scalar_summary(loss_val-total_loss, 'validation_delta', 'losses')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_step_fn(sess, train_op, global_step, train_step_kwargs):\n",
    "    \"\"\"\n",
    "    slim.learning.train_step():\n",
    "    train_step_kwargs = {summary_writer:, should_log:, should_stop:}\n",
    "    \"\"\"\n",
    "#     train_step_fn.step += 1  # or use global_step.eval(session=sess)\n",
    "    input_path = np.array([image_by_type_train[i][\"path\"].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "    input_images = np.array([imageio.imread(i) for i in input_path]).astype(np.float32)\n",
    "    labels = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "    input_images, labels = shuffle(input_images, labels)\n",
    "    labels = one_hot_encoder.transform(labels).toarray()\n",
    "    \n",
    "    sess.run([img_assign,label_assign], feed_dict={img_holder:input_images, label_holder:labels})\n",
    "#     print sess.run([img,label])\n",
    "\n",
    "    # calc training losses\n",
    "    total_loss, should_stop = slim.learning.train_step(sess, train_op, global_step, train_step_kwargs)\n",
    "\n",
    "\n",
    "    # validate on interval\n",
    "    if global_step.eval(session=sess) % VALIDATION_INTERVAL == 0:\n",
    "        input_path_val = np.array([image_by_type_val[i][\"path\"].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "        input_images_val = np.array([imageio.imread(i) for i in input_path_val]).astype(np.float32)\n",
    "        labels_val = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "        input_images_val, labels_val = shuffle(input_images_val, labels_val)\n",
    "        labels_val = one_hot_encoder.transform(labels_val).toarray()\n",
    "        \n",
    "        sess.run([img_assign_val,label_assign_val,logits_val], feed_dict={img_holder_val:input_images_val, label_holder_val:labels_val})\n",
    "        validiate_loss = sess.run(loss_val)\n",
    "    \n",
    "        \n",
    "    print(\">> global step {}:    train={}   validation={}  delta={}\".format(global_step.eval(session=sess), \n",
    "                        total_loss, loss_val, loss_val-total_loss))\n",
    "\n",
    "\n",
    "    return [total_loss, should_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "        \n",
    "#     tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, )\n",
    "    \n",
    "    input_path = np.array([image_by_type_train[i][\"path\"].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "    input_images = np.array([imageio.imread(i) for i in input_path]).astype(np.float32)\n",
    "#     input_size = np.shape(input_images)[0]\n",
    "    labels = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "    input_images, labels = shuffle(input_images, labels)\n",
    "    labels = one_hot_encoder.transform(labels).toarray()\n",
    "    \n",
    "    input_path_val = np.array([image_by_type_val[i][\"path\"].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "    input_images_val = np.array([imageio.imread(i) for i in input_path_val]).astype(np.float32)\n",
    "    labels_val = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "    input_images_val, labels_val = shuffle(input_images_val, labels_val)\n",
    "    labels_val = one_hot_encoder.transform(labels_val).toarray()\n",
    "\n",
    "    slim.learning.train(\n",
    "        train_tensor,\n",
    "        LOG_DIR,\n",
    "        log_every_n_steps=1,\n",
    "        number_of_steps=MAX_EPOCH,\n",
    "        graph=g,\n",
    "        save_summaries_secs=60,\n",
    "        save_interval_secs=300,\n",
    "        init_fn=get_checkpoint_init_fn(),\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        train_step_fn = train_step_fn,\n",
    "        session_config=session_config,\n",
    "        init_feed_dict = {img_holder:input_images, label_holder:labels, img_holder_val: input_images_val, label_holder_val: labels_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/model.ckpt-24753\n",
      "0.47619047619047616\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"./saved_model/model.ckpt-24753\")\n",
    "        input_path = np.array([image_by_type_val[i][\"path\"].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "        input_images = np.array([imageio.imread(i) for i in input_path]).astype(np.float32)\n",
    "        labels = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "        input_images, labels = shuffle(input_images, labels)\n",
    "        labels = one_hot_encoder.transform(labels).toarray()\n",
    "        sess.run([img_assign, label_assign], feed_dict = {img_holder:input_images, label_holder:labels})\n",
    "        predict = sess.run([tf.argmax(logits[i]) for i in range(input_size)])\n",
    "        true_value = [np.argmax(labels[i]) for i in range(input_size)]\n",
    "        print np.sum(predict == np.array(true_value)) / len(true_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
