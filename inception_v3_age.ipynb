{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaoqitong/anaconda/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nets import inception_utils, inception_v3\n",
    "from glob import glob\n",
    "import imageio\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_checkpoint_init_fn():\n",
    "    # Load from .ckpt file\n",
    "    variables_to_restore = slim.get_variables_to_restore(exclude=[\"InceptionV3/Logits/Conv2d_1c_1x1/weights:0\", \"InceptionV3/Logits/Conv2d_1c_1x1/biases:0\"])\n",
    "    global_step_reset = tf.assign(tf.train.get_or_create_global_step(), 0)\n",
    "    slim_init_fn = slim.assign_from_checkpoint_fn(\"./inception_v3.ckpt\",variables_to_restore,ignore_missing_vars=True)\n",
    "    return slim_init_fn\n",
    "\n",
    "# Load Data\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "arg_scope = tf.contrib.framework.arg_scope\n",
    "\n",
    "# Set Params\n",
    "MAX_EPOCH = 150000\n",
    "NUM_CLASSES = 4\n",
    "NUM_IMG_FROM_EACH_CLASS = 15\n",
    "input_size = NUM_IMG_FROM_EACH_CLASS * NUM_CLASSES\n",
    "VALIDATION_INTERVAL = 500\n",
    "START_LR = 1e-04\n",
    "DECAY_STEP = 10000 / 63 * 10\n",
    "DECAY_RATE = 0.98\n",
    "RETRAIN_NAMES = [\"Logits\", \"Mixed_7\"]\n",
    "\n",
    "if sys.platform == \"darwin\":\n",
    "    base_skin_dir = os.path.join('./Data/')\n",
    "    LOG_DIR = \"./saved_model_test_age/Inception_\" + str(START_LR) + \"_\" + str(DECAY_STEP) + \"_\" + str(DECAY_RATE) + \"_\" + RETRAIN_NAMES[-1]\n",
    "else:\n",
    "    base_skin_dir = os.path.join('/datacommons/plusds/skin_cancer/team2')\n",
    "    LOG_DIR = \"/work/qg26/saved_model_age/Inception_\" + str(START_LR) + \"_\" + str(DECAY_STEP) + \"_\" + str(DECAY_RATE) + \"_\" + RETRAIN_NAMES[-1]\n",
    "\n",
    "\n",
    "session_config = tf.ConfigProto(log_device_placement=False)\n",
    "session_config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary for Loading Resized Images\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(base_skin_dir, 'HAM10000_images_part_[1-2]_resize', '*.jpg'))}\n",
    "\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'dermatofibroma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Side Information DataFrame\n",
    "\n",
    "side_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\n",
    "side_df['path'] = side_df['image_id'].map(imageid_path_dict.get)\n",
    "side_df['cell_type'] = side_df['dx'].map(lesion_type_dict.get) \n",
    "side_df['cell_type_idx'] = pd.Categorical(side_df['cell_type']).codes\n",
    "\n",
    "side_df = side_df.dropna()\n",
    "side_df = side_df[side_df[\"localization\"]!=\"unknown\"]\n",
    "side_df = side_df[side_df[\"sex\"]!=\"unknown\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25    40.0\n",
       "0.50    50.0\n",
       "0.75    65.0\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "side_df[\"age\"].quantile([0.25,0.5,0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_age(age):\n",
    "    if age <= 40:\n",
    "        return 0\n",
    "    elif age <= 50:\n",
    "        return 1\n",
    "    elif age <= 65:\n",
    "        return 2\n",
    "    return 3\n",
    "\n",
    "side_df[\"age_train\"] = side_df[\"age\"].map(class_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_by_type = [side_df.iloc[np.array(side_df[\"age_train\"] == i)] for i in range(4)]\n",
    "image_by_type_train = [i.head(int(np.ceil(len(i)*0.8))) for i in image_by_type]\n",
    "image_by_type_val = [j.head(int(np.ceil(len(j)*0.5))) for j in [i.tail(int(np.floor(len(i)*0.2))) for i in image_by_type] ]\n",
    "image_by_type_test = [i.tail(int(np.floor(len(i)*0.1))) for i in image_by_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Graph\n",
    "one_hot_encoder = OneHotEncoder(4)\n",
    "one_hot_encoder.fit(np.arange(4).reshape(-1,1))\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    img_holder = tf.placeholder(shape=[input_size,299,299,3], dtype=tf.float32, name=\"Img_Holder\")\n",
    "    label_holder = tf.placeholder(shape=[input_size,4], dtype=tf.float32, name=\"Label_Holder\")\n",
    "    img = tf.Variable(img_holder, name=\"Img_Var\", trainable=False)\n",
    "    label = tf.Variable(label_holder, name=\"Label_Var\", trainable=False)\n",
    "    img_assign = img.assign(img_holder, name=\"Img_Assign\")\n",
    "    label_assign = label.assign(label_holder, name=\"Label_Assign\")\n",
    "    \n",
    "    img_holder_val = tf.placeholder(shape=[input_size,299,299,3], dtype=tf.float32, name=\"Img_Holder_val\")\n",
    "    label_holder_val = tf.placeholder(shape=[input_size,4], dtype=tf.float32, name=\"Label_Holder_val\")\n",
    "    img_val = tf.Variable(img_holder_val, name=\"Img_Var_val\", trainable=False)\n",
    "    label_val = tf.Variable(label_holder_val, name=\"Label_Var_val\", trainable=False)\n",
    "    img_assign_val = img_val.assign(img_holder_val, name=\"Img_Assign_val\")\n",
    "    label_assign_val = label_val.assign(label_holder_val, name=\"Label_Assign_val\")\n",
    "\n",
    "    with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n",
    "        logits, end_points = inception_v3.inception_v3(img, num_classes=4, create_aux_logits=False, is_training=True)\n",
    "        pred = slim.softmax(logits, scope=\"Prediction\")\n",
    "        logits_val, _ = inception_v3.inception_v3(img_val, num_classes=4, create_aux_logits=False, is_training=False, reuse=tf.AUTO_REUSE)\n",
    "        pred_val = slim.softmax(logits_val, scope=\"Prediction_Val\")\n",
    "    _, accuracy_val = tf.metrics.accuracy(tf.math.argmax(pred_val, axis=1), tf.math.argmax(label_val, axis=1))\n",
    "    \n",
    "    loss = tf.losses.softmax_cross_entropy(label, logits)\n",
    "    total_loss = tf.losses.get_total_loss()\n",
    "    loss_val = tf.losses.softmax_cross_entropy(label_val, logits_val, loss_collection=\"validation\")\n",
    "    \n",
    "    retrain_list = []\n",
    "    for v in tf.trainable_variables():\n",
    "        for n in RETRAIN_NAMES:\n",
    "            if n in v.name:\n",
    "                retrain_list += [v]\n",
    "    \n",
    "    learning_rate = tf.train.exponential_decay(START_LR, tf.train.get_or_create_global_step(), DECAY_STEP, DECAY_RATE)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_tensor = slim.learning.create_train_op(total_loss, optimizer=opt, variables_to_train=retrain_list)\n",
    "    # Creat Summary\n",
    "    slim.summaries.add_scalar_summary(total_loss, 'cross_entropy_loss', 'losses')\n",
    "    slim.summaries.add_scalar_summary(learning_rate, 'learning_rate', 'training')\n",
    "    slim.summaries.add_scalar_summary(loss_val, 'validation_loss', 'losses')\n",
    "    slim.summaries.add_scalar_summary(loss_val-total_loss, 'validation_delta', 'losses')\n",
    "    slim.summaries.add_scalar_summary(accuracy_val, 'validation_accuracy', 'accuracy')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_step_fn(sess, train_op, global_step, train_step_kwargs):\n",
    "    \"\"\"\n",
    "    slim.learning.train_step():\n",
    "    train_step_kwargs = {summary_writer:, should_log:, should_stop:}\n",
    "    \"\"\"\n",
    "#     train_step_fn.step += 1  # or use global_step.eval(session=sess)\n",
    "    input_df = [image_by_type_train[i].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]\n",
    "    input_path = np.array([input_df[i][\"path\"] for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "    input_images = np.array([imageio.imread(i) for i in input_path]).astype(np.float32)\n",
    "\n",
    "    labels = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "\n",
    "    input_images, labels = shuffle(input_images, labels)\n",
    "    labels = one_hot_encoder.transform(labels).toarray()\n",
    "    \n",
    "    sess.run([img_assign,label_assign], feed_dict={img_holder:input_images, label_holder:labels})\n",
    "#     print sess.run([img,label])\n",
    "\n",
    "    # calc training losses\n",
    "    total_loss, should_stop = slim.learning.train_step(sess, train_op, global_step, train_step_kwargs)\n",
    "\n",
    "\n",
    "    # validate on interval\n",
    "    if global_step.eval(session=sess) % VALIDATION_INTERVAL == 0:\n",
    "        input_df_val = [image_by_type_val[i].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]\n",
    "        input_path_val = np.array([input_df_val[i][\"path\"].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "        input_images_val = np.array([imageio.imread(i) for i in input_path_val]).astype(np.float32)\n",
    "\n",
    "        labels_val = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "\n",
    "        input_images_val, labels_val = shuffle(input_images_val, labels_val)\n",
    "        labels_val = one_hot_encoder.transform(labels_val).toarray()\n",
    "        \n",
    "        sess.run([img_assign_val,label_assign_val,logits_val,accuracy_val], \n",
    "                 feed_dict={img_holder_val:input_images_val, label_holder_val:labels_val})\n",
    "        validiate_loss = sess.run(loss_val)\n",
    "    \n",
    "        \n",
    "#    print(\">> global step {}:    train={}   validation={}  delta={}\".format(global_step.eval(session=sess), \n",
    "#                        total_loss, loss_val, loss_val-total_loss))\n",
    "\n",
    "\n",
    "    return [total_loss, should_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Logits/Conv2d_1c_1x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Logits/Conv2d_1c_1x1/biases/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable Label_Var_val missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/weights/Adam missing in checkpoint ./inception_v3.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Logits/Conv2d_1c_1x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable Img_Var_val missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable beta1_power missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable Img_Var missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/weights/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Logits/Conv2d_1c_1x1/biases/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable beta2_power missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Adam_1 missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable Label_Var missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/weights/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:Variable InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Adam missing in checkpoint ./inception_v3.ckpt\n",
      "WARNING:tensorflow:From /Users/gaoqitong/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/learning.py:737: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "INFO:tensorflow:Restoring parameters from ./inception_v3.ckpt\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f27576ed977f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtrain_step_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0msession_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         init_feed_dict = {img_holder:input_images, label_holder:labels, img_holder_val: input_images_val, label_holder_val: labels_val})\n\u001b[0m",
      "\u001b[0;32m/Users/gaoqitong/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/learning.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_op, logdir, train_step_fn, train_step_kwargs, log_every_n_steps, graph, master, is_chief, global_step, number_of_steps, init_op, init_feed_dict, local_init_op, init_fn, ready_op, summary_op, save_summaries_secs, summary_writer, startup_delay_steps, saver, save_interval_secs, sync_optimizer, session_config, session_wrapper, trace_every_n_steps, ignore_live_threads)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0mshould_retry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       with sv.managed_session(\n\u001b[0;32m--> 748\u001b[0;31m           master, start_standard_services=False, config=session_config) as sess:\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msession_wrapper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gaoqitong/anaconda/envs/py27/lib/python2.7/contextlib.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gaoqitong/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/training/supervisor.pyc\u001b[0m in \u001b[0;36mmanaged_session\u001b[0;34m(self, master, config, start_standard_services, close_summary_writer)\u001b[0m\n\u001b[1;32m    991\u001b[0m       sess = self.prepare_or_wait_for_session(\n\u001b[1;32m    992\u001b[0m           \u001b[0mmaster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m           start_standard_services=start_standard_services)\n\u001b[0m\u001b[1;32m    994\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gaoqitong/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/training/supervisor.pyc\u001b[0m in \u001b[0;36mprepare_or_wait_for_session\u001b[0;34m(self, master, config, wait_for_checkpoint, max_wait_secs, start_standard_services)\u001b[0m\n\u001b[1;32m    729\u001b[0m           \u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m           init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)\n\u001b[0;32m--> 731\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mstart_standard_services\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting standard services.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gaoqitong/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/training/supervisor.pyc\u001b[0m in \u001b[0;36m_write_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_summary_writer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_added_to_summary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_summary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_summary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_added_to_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gaoqitong/anaconda/envs/py27/lib/python2.7/site-packages/tensorflow/python/summary/writer/writer.pyc\u001b[0m in \u001b[0;36madd_meta_graph\u001b[0;34m(self, meta_graph_def, global_step)\u001b[0m\n\u001b[1;32m    244\u001b[0m       raise TypeError(\"meta_graph_def must be type MetaGraphDef, saw type: %s\" %\n\u001b[1;32m    245\u001b[0m                       type(meta_graph_def))\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mmeta_graph_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_graph_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    \n",
    "    # Train Set    \n",
    "    input_df = [image_by_type_train[i].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]\n",
    "    input_path = np.array([input_df[i][\"path\"] for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "    input_images = np.array([imageio.imread(i) for i in input_path]).astype(np.float32)\n",
    "\n",
    "    labels = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "\n",
    "    input_images, labels = shuffle(input_images, labels)\n",
    "    labels = one_hot_encoder.transform(labels).toarray()\n",
    "    \n",
    "    # Val Set\n",
    "    input_df_val = [image_by_type_val[i].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]\n",
    "    input_path_val = np.array([input_df_val[i][\"path\"].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "    input_images_val = np.array([imageio.imread(i) for i in input_path_val]).astype(np.float32)\n",
    "\n",
    "    labels_val = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "\n",
    "    input_images_val, labels_val = shuffle(input_images_val, labels_val)\n",
    "    labels_val = one_hot_encoder.transform(labels_val).toarray()\n",
    "\n",
    "    slim.learning.train(\n",
    "        train_tensor,\n",
    "        LOG_DIR,\n",
    "        log_every_n_steps=1,\n",
    "        number_of_steps=MAX_EPOCH,\n",
    "        graph=g,\n",
    "        save_summaries_secs=60,\n",
    "        save_interval_secs=300,\n",
    "        init_fn=get_checkpoint_init_fn(),\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        train_step_fn = train_step_fn,\n",
    "        session_config=session_config,\n",
    "        init_feed_dict = {img_holder:input_images, label_holder:labels, img_holder_val: input_images_val, label_holder_val: labels_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"./saved_model/Inception_0.0001_476.19047619_0.96/model.ckpt-50000\")\n",
    "        input_path = np.array([image_by_type_val[i][\"path\"].sample(NUM_IMG_FROM_EACH_CLASS) for i in range(NUM_CLASSES)]).reshape(-1)\n",
    "        input_images = np.array([imageio.imread(i) for i in input_path]).astype(np.float32)\n",
    "        labels = np.array([[i]*NUM_IMG_FROM_EACH_CLASS for i in range(NUM_CLASSES)]).reshape(-1,1)\n",
    "        input_images, labels = shuffle(input_images, labels)\n",
    "        labels = one_hot_encoder.transform(labels).toarray()\n",
    "        sess.run([img_assign, label_assign], feed_dict = {img_holder:input_images, label_holder:labels})\n",
    "        predict = sess.run([tf.argmax(logits[i]) for i in range(input_size)])\n",
    "        true_value = [np.argmax(labels[i]) for i in range(input_size)]\n",
    "        print np.sum(predict == np.array(true_value)) / len(true_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "loss = []\n",
    "with g.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"./saved_model/Inception_0.0001_476.19047619_0.96/model.ckpt-50000\")\n",
    "        for c in range(NUM_CLASSES):\n",
    "            current_loss = []\n",
    "            input_path = np.array([image_by_type_val[c][\"path\"].values]).reshape(-1)\n",
    "            all_input_images = np.array([imageio.imread(i) for i in input_path]).astype(np.float32)\n",
    "            all_labels = np.array([[c]*len(image_by_type_val[c])]).reshape(-1,1)\n",
    "#             input_images, labels = shuffle(input_images, labels)\n",
    "            all_labels = one_hot_encoder.transform(all_labels).toarray()\n",
    "            for k in range(int(np.ceil(len(image_by_type_val[c])/input_size))):\n",
    "                if k != int(np.ceil(len(image_by_type_val[c])/input_size))-1:\n",
    "                    input_images = all_input_images[k*input_size:(k+1)*input_size]\n",
    "                    labels = all_labels[k*input_size:(k+1)*input_size]\n",
    "                    sess.run([img_assign, label_assign], feed_dict = {img_holder:input_images, label_holder:labels})\n",
    "                    predict = sess.run([tf.argmax(logits[i]) for i in range(input_size)])\n",
    "                    true_value = [np.argmax(labels[i]) for i in range(input_size)]\n",
    "                    current_loss += [np.sum(predict == np.array(true_value)) / len(true_value)]\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "            print current_loss\n",
    "            loss += [np.mean(current_loss)]\n",
    "#             count += input_size\n",
    "#             if count >= sum([len(i) for i in image_by_type_val]):\n",
    "#                 break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
